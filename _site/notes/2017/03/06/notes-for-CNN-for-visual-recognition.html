<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title> Notes for CNN for Visual Recognition! — A Course by Stanford &raquo;  Sancheeta Kaushal</title>
<meta name="description" content="Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.
">
<meta name="keywords" content="">
<link rel="canonical" href="http://hitchhiker.ma/notes/2017/03/06/notes-for-CNN-for-visual-recognition.html">
        




<!-- Twitter Cards -->
<meta name="twitter:card" content="summary" />
<meta name="twitter:title" content="Notes for CNN for Visual Recognition!" />
<meta name="twitter:description" content="Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.
" />
<meta name="twitter:image" content="http://hitchhiker.ma" />

<!-- Google plus -->
<meta name="author" content="https://www.google.com/+MotaquillahMaddane">
<link rel="author" href="https://www.google.com/+MotaquillahMaddane">

<!-- Open Graph -->
<meta property="og:locale" content="">
<meta property="og:type" content="article">
<meta property="og:title" content="Notes for CNN for Visual Recognition!">
<meta property="og:description" content="Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.
">
<meta property="og:url" content="http://hitchhiker.ma/notes/2017/03/06/notes-for-CNN-for-visual-recognition.html">
<meta property="og:site_name" content="Sancheeta Kaushal">

        <link href='http://fonts.googleapis.com/css?family=Inconsolata:400,700' rel='stylesheet' type='text/css'>
<link rel="stylesheet" href="/assets/vendor/normalize-css/normalize.css">
<link rel="stylesheet" href="/css/main.css">

  <link rel="stylesheet" href="/assets/vendor/highlight/styles/solarized_dark.css">

<link rel="stylesheet" href="/assets/vendor/font-awesome/css/font-awesome.css">
    </head>

    <body>
        <div class="wrapper">
            <header class="header">
    <div class="navigation">
        <a href="/" class="logo">Sancheeta Kaushal</a>

        <ul class="menu">
            <li class="menu__entry"><a href="/about">About</a></li>
            <li class="menu__entry"><a href="/">Blog</a></li>
            <li class="menu__entry"><a href="https://drive.google.com/open?id=0B00_UkobfItZXzFXTm5vUEV2MWc" target='_blank'>Resume</a></li>
        </ul>
    </div>

    <ul class="social-links">
        
            <a href="https://github.com/sanchee16" class="social-links__entry" target="_blank">
                <i class="fa fa-github"></i>
            </a>
        

        
            <a href="https://twitter.com/sanchee15" class="social-links__entry" target="_blank">
                <i class="fa fa-twitter"></i>
            </a>
        
    </ul>
</header>

            <h1 class="page-title post-title">
    <div class="page-title__text post-title__text">Notes for CNN for Visual Recognition!</div>
    <div class="page-title__subtitle post-title__subtitle">A Course by Stanford</div>
</h1>

<div class="content">
    <p>Lesson 2:</p>

<ul>
  <li>Image Classification</li>
  <li>Semantic Gap - Representation of image on computer as numbers</li>
  <li>Challenges are:
    <ul>
      <li>Viewpoint Variation - Camera rotations lead to changes in brightness.</li>
      <li>Illumination issues</li>
      <li>Deformation</li>
      <li>Occlusion</li>
      <li>Background Clutter</li>
      <li>Intraclass Variation</li>
    </ul>
  </li>
  <li>Follow a data-driven approach i.e. Collect dataset of images and labels, use ML algos to train an image 
classifier and evaluate classifier on test images.</li>
  <li>Nearest Neighbour Classifier - Use Manhattan distance</li>
  <li>Do more compute at train time but prediction should be constant time computation.</li>
  <li>Aside - Approximate Nearest Neighbour (FLANN)</li>
  <li>Hyper-parameter - Distance, and the value of k for kNN</li>
  <li>Training data, validation data and training data set or Cross Validation</li>
  <li>Linear Classification</li>
  <li>NN can see, hear, translate, control and think.</li>
</ul>

<p>Lecture 4:</p>

<ul>
  <li>Forward pass gives loss and backward pass gives gradients</li>
  <li>Gradient Descent
    <ul>
      <li>Numerical which is slow and approx but easy to write</li>
      <li>Analytical which is fast and exact but error prone</li>
    </ul>
  </li>
  <li>Computational Graph is huge for Neural Turing Machine</li>
  <li>Chain rule for backprop</li>
  <li>Local gradients are computed at the time of forward pass and can be chained to global gradient later at the time of backprop.</li>
  <li>For plus gate, during back prop, the value for the next gate is 1 * the previous value.</li>
  <li>For multiplicative gate, during back prop, the value for the next gate is the value of other input * the previous value.</li>
  <li>Hence, add gate is gradient distributor, the max gate is gradient router and mul gate can be the gradient switcher.</li>
  <li>At branches, gradients are added according to multivariate chain rule.</li>
  <li>Graph class with nodes topologically sorted and forward and backward function</li>
  <li>Lot of memory required to store intermediate results that will be used during back prop</li>
  <li>For vectors, we have jacobian matrix which stores derivative of each element of output wrt input</li>
  <li>Vectorized Operations</li>
  <li>Jacobian matrix is not always a full matrix and is a sparse matrix because there are values only on the diagonal and even not all those values are be used.</li>
  <li>Backpropagation is recursive application of chain rule along computational graph to computer gradients  of all inputs/params/intermediates</li>
  <li>Biological description of neurons
    <ul>
      <li>Soma: cell body</li>
      <li>Dendrites: listeners/input</li>
      <li>Axon: terminals/output</li>
    </ul>
  </li>
  <li>Activation functions
    <ul>
      <li>Sigmoid</li>
      <li>tanh</li>
      <li>ReLU</li>
      <li>Maxout</li>
      <li>Leaky ReLU</li>
      <li>ELU</li>
    </ul>
  </li>
  <li>Fully connected layer and hidden layers</li>
  <li>Kernel trick changes data representation to a space where it’s linearly separable</li>
</ul>

<p>Lecture 5:</p>

<ul>
  <li>People hardly train CNN from scratch. Pretraining and fine tuning is used.</li>
  <li>Transfer Learning
    <ul>
      <li>Train network on Imagenet</li>
      <li>If small dataset, fix all weights retrain only the classifier on your data. Here CNN is treated as fixed feature extractor.</li>
      <li>If medium sized dataset, use old weights as initialization, train the full network or only some of the higher layers. eg. Caffe Model Zoo</li>
    </ul>
  </li>
  <li>History
    <ul>
      <li>Perceptron</li>
      <li>Multilayer Perceptron</li>
      <li>Back Propagation Rules</li>
      <li>Reinvigorated Research in Deep Learning</li>
      <li>Imagenet Classification With Deep CNN
        <ul>
          <li>Better ways of Initialization</li>
          <li>GPUs</li>
          <li>More data</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Activation Function
    <ul>
      <li>Sigmoid
        <ul>
          <li>Squashing Function to [0, 1]</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>


</div>

<div class="about">
    <div class="about__devider">*****</div>
    <div class="about__text">
        Written by <strong>  Sancheeta Kaushal </strong>
        on <strong>06 March 2017</strong>
    </div>
</div>


        </div>

        <script src="/assets/vendor/highlight/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
        
    </body>
</html>